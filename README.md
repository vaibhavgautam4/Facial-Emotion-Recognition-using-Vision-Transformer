# Facial Emotion Recognition using Vision Transformer
 
Spearheaded the creation of a facial emotion detection model using VIT and MobileNet architectures.
we have tried and tested VIT transfer model to learn features and able to recognize them with more accuracy and precision.
A Model that can Understand and Extract Human emotions from a given image efficiently.

- Demonstrated proficiency in computer vision, leading the development of the emotion detection model.

- Looking forward to Translate model capabilities into a practical web application,enabling real-time emotion analysis for users.

### Installation
- Create a Conda environment or a Virtual Environment based on your convinience.

- Open terminal in the directory where the environment is created or can use CLI from any Code Editor terminal.

- make sure you have ``` Python>=3.10 ``` installed on your machine.

- install other dependencies and libraries using the command:

```
pip install requirement.txt
```

- Once all the requirements are installed run the **vision_transformer_and_other_cnn's.ipynb** by connecting to the kernel you made and running cells according to requirements.

- As the structure may be not in sequence, you are advised to check your requirements and run the files accordingly.

### Datasets Used

- [FER 2013](https://www.kaggle.com/datasets/msambare/fer2013) Dataset is used for the training of model.

### Results
- will be added soon.
